{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.10 64-bit ('deeplearning': conda)",
   "display_name": "Python 3.6.10 64-bit ('deeplearning': conda)",
   "metadata": {
    "interpreter": {
     "hash": "94798a07477d283dccef05b0adbefc0f5fa0f7f1dab85cfae6230d25b548a807"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(weight, input):\n",
    "    return weight * input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = np.array([0.3])\n",
    "input = np.array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.3])"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "neural_network(weight, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = neural_network(weight, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_pred, y_true):\n",
    "    return (y_pred - y_true) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([-0.5])"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "y_pred - y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Prediction: [0.3], loss: [0.25]\nPrediction: [0.8], loss: [0.]\nPrediction: [0.8], loss: [0.]\nPrediction: [0.8], loss: [0.]\nPrediction: [0.8], loss: [0.]\nPrediction: [0.8], loss: [0.]\nPrediction: [0.8], loss: [0.]\nPrediction: [0.8], loss: [0.]\nPrediction: [0.8], loss: [0.]\nPrediction: [0.8], loss: [0.]\nPrediction: [0.8], loss: [0.]\nPrediction: [0.8], loss: [0.]\nPrediction: [0.8], loss: [0.]\nPrediction: [0.8], loss: [0.]\nPrediction: [0.8], loss: [0.]\nPrediction: [0.8], loss: [0.]\nPrediction: [0.8], loss: [0.]\nPrediction: [0.8], loss: [0.]\nPrediction: [0.8], loss: [0.]\nPrediction: [0.8], loss: [0.]\n"
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    y_pred = neural_network(weight, input)\n",
    "    error = mse(y_pred, y_true)\n",
    "    print(f\"Prediction: {y_pred}, loss: {error}\")\n",
    "    value = y_pred - y_true\n",
    "    grad = value * input\n",
    "    weight = weight - grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent iterations with very low learning_rate\n",
    "learning_rate = 0.001\n",
    "\n",
    "weight = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Prediction: [0.30990557], loss: [0.24019255]\nPrediction: [0.31039566], loss: [0.23971241]\nPrediction: [0.31088527], loss: [0.23923322]\nPrediction: [0.31137438], loss: [0.238755]\nPrediction: [0.31186301], loss: [0.23827772]\nPrediction: [0.31235114], loss: [0.23780141]\nPrediction: [0.31283879], loss: [0.23732604]\nPrediction: [0.31332595], loss: [0.23685163]\nPrediction: [0.31381263], loss: [0.23637816]\nPrediction: [0.31429882], loss: [0.23590564]\nPrediction: [0.31478452], loss: [0.23543407]\nPrediction: [0.31526973], loss: [0.23496343]\nPrediction: [0.31575446], loss: [0.23449374]\nPrediction: [0.31623871], loss: [0.23402499]\nPrediction: [0.31672247], loss: [0.23355717]\nPrediction: [0.31720575], loss: [0.23309029]\nPrediction: [0.31768854], loss: [0.23262434]\nPrediction: [0.31817085], loss: [0.23215933]\nPrediction: [0.31865268], loss: [0.23169524]\nPrediction: [0.31913403], loss: [0.23123208]\nPrediction: [0.31961489], loss: [0.23076985]\nPrediction: [0.32009528], loss: [0.23030854]\nPrediction: [0.32057518], loss: [0.22984815]\nPrediction: [0.32105461], loss: [0.22938869]\nPrediction: [0.32153355], loss: [0.22893014]\nPrediction: [0.32201202], loss: [0.22847251]\nPrediction: [0.32249001], loss: [0.22801579]\nPrediction: [0.32296752], loss: [0.22755999]\nPrediction: [0.32344455], loss: [0.2271051]\nPrediction: [0.32392111], loss: [0.22665111]\nPrediction: [0.32439719], loss: [0.22619804]\nPrediction: [0.32487279], loss: [0.22574587]\nPrediction: [0.32534792], loss: [0.2252946]\nPrediction: [0.32582257], loss: [0.22484424]\nPrediction: [0.32629675], loss: [0.22439477]\nPrediction: [0.32677045], loss: [0.22394621]\nPrediction: [0.32724368], loss: [0.22349854]\nPrediction: [0.32771643], loss: [0.22305177]\nPrediction: [0.32818872], loss: [0.22260589]\nPrediction: [0.32866053], loss: [0.2221609]\nPrediction: [0.32913187], loss: [0.2217168]\nPrediction: [0.32960274], loss: [0.22127359]\nPrediction: [0.33007313], loss: [0.22083126]\nPrediction: [0.33054306], loss: [0.22038982]\nPrediction: [0.33101252], loss: [0.21994926]\nPrediction: [0.33148151], loss: [0.21950958]\nPrediction: [0.33195002], loss: [0.21907078]\nPrediction: [0.33241807], loss: [0.21863286]\nPrediction: [0.33288566], loss: [0.21819581]\nPrediction: [0.33335277], loss: [0.21775964]\nPrediction: [0.33381942], loss: [0.21732434]\nPrediction: [0.3342856], loss: [0.2168899]\nPrediction: [0.33475131], loss: [0.21645634]\nPrediction: [0.33521656], loss: [0.21602364]\nPrediction: [0.33568134], loss: [0.21559181]\nPrediction: [0.33614566], loss: [0.21516085]\nPrediction: [0.33660952], loss: [0.21473074]\nPrediction: [0.33707291], loss: [0.21430149]\nPrediction: [0.33753584], loss: [0.2138731]\nPrediction: [0.3379983], loss: [0.21344557]\nPrediction: [0.3384603], loss: [0.21301889]\nPrediction: [0.33892184], loss: [0.21259307]\nPrediction: [0.33938292], loss: [0.2121681]\nPrediction: [0.33984354], loss: [0.21174397]\nPrediction: [0.34030369], loss: [0.2113207]\nPrediction: [0.34076339], loss: [0.21089827]\nPrediction: [0.34122263], loss: [0.21047668]\nPrediction: [0.3416814], loss: [0.21005594]\nPrediction: [0.34213972], loss: [0.20963603]\nPrediction: [0.34259758], loss: [0.20921697]\nPrediction: [0.34305498], loss: [0.20879875]\nPrediction: [0.34351193], loss: [0.20838136]\nPrediction: [0.34396842], loss: [0.2079648]\nPrediction: [0.34442445], loss: [0.20754908]\nPrediction: [0.34488002], loss: [0.20713419]\nPrediction: [0.34533514], loss: [0.20672013]\nPrediction: [0.34578981], loss: [0.2063069]\nPrediction: [0.34624402], loss: [0.20589449]\nPrediction: [0.34669778], loss: [0.20548291]\nPrediction: [0.34715108], loss: [0.20507215]\nPrediction: [0.34760393], loss: [0.20466221]\nPrediction: [0.34805632], loss: [0.20425309]\nPrediction: [0.34850827], loss: [0.20384479]\nPrediction: [0.34895976], loss: [0.2034373]\nPrediction: [0.3494108], loss: [0.20303063]\nPrediction: [0.34986139], loss: [0.20262477]\nPrediction: [0.35031153], loss: [0.20221972]\nPrediction: [0.35076121], loss: [0.20181549]\nPrediction: [0.35121045], loss: [0.20141206]\nPrediction: [0.35165924], loss: [0.20100943]\nPrediction: [0.35210758], loss: [0.20060762]\nPrediction: [0.35255548], loss: [0.2002066]\nPrediction: [0.35300292], loss: [0.19980639]\nPrediction: [0.35344992], loss: [0.19940698]\nPrediction: [0.35389647], loss: [0.19900836]\nPrediction: [0.35434257], loss: [0.19861054]\nPrediction: [0.35478823], loss: [0.19821352]\nPrediction: [0.35523344], loss: [0.19781729]\nPrediction: [0.35567821], loss: [0.19742186]\nPrediction: [0.35612253], loss: [0.19702721]\nPrediction: [0.35656641], loss: [0.19663335]\nPrediction: [0.35700984], loss: [0.19624028]\nPrediction: [0.35745283], loss: [0.195848]\nPrediction: [0.35789538], loss: [0.1954565]\nPrediction: [0.35833748], loss: [0.19506578]\nPrediction: [0.35877914], loss: [0.19467584]\nPrediction: [0.35922037], loss: [0.19428669]\nPrediction: [0.35966114], loss: [0.19389831]\nPrediction: [0.36010148], loss: [0.1935107]\nPrediction: [0.36054138], loss: [0.19312388]\nPrediction: [0.36098084], loss: [0.19273782]\nPrediction: [0.36141986], loss: [0.19235254]\nPrediction: [0.36185844], loss: [0.19196803]\nPrediction: [0.36229658], loss: [0.19158428]\nPrediction: [0.36273429], loss: [0.19120131]\nPrediction: [0.36317155], loss: [0.19081909]\nPrediction: [0.36360838], loss: [0.19043765]\nPrediction: [0.36404477], loss: [0.19005696]\nPrediction: [0.36448073], loss: [0.18967704]\nPrediction: [0.36491625], loss: [0.18929787]\nPrediction: [0.36535133], loss: [0.18891947]\nPrediction: [0.36578598], loss: [0.18854182]\nPrediction: [0.36622019], loss: [0.18816492]\nPrediction: [0.36665397], loss: [0.18778878]\nPrediction: [0.36708732], loss: [0.18741339]\nPrediction: [0.36752023], loss: [0.18703875]\nPrediction: [0.36795271], loss: [0.18666486]\nPrediction: [0.36838476], loss: [0.18629172]\nPrediction: [0.36881637], loss: [0.18591932]\nPrediction: [0.36924756], loss: [0.18554767]\nPrediction: [0.36967831], loss: [0.18517676]\nPrediction: [0.37010863], loss: [0.18480659]\nPrediction: [0.37053852], loss: [0.18443716]\nPrediction: [0.37096798], loss: [0.18406847]\nPrediction: [0.37139702], loss: [0.18370052]\nPrediction: [0.37182562], loss: [0.1833333]\nPrediction: [0.37225379], loss: [0.18296682]\nPrediction: [0.37268154], loss: [0.18260107]\nPrediction: [0.37310886], loss: [0.18223605]\nPrediction: [0.37353575], loss: [0.18187176]\nPrediction: [0.37396221], loss: [0.1815082]\nPrediction: [0.37438825], loss: [0.18114536]\nPrediction: [0.37481386], loss: [0.18078325]\nPrediction: [0.37523905], loss: [0.18042187]\nPrediction: [0.37566381], loss: [0.1800612]\nPrediction: [0.37608815], loss: [0.17970126]\nPrediction: [0.37651206], loss: [0.17934204]\nPrediction: [0.37693555], loss: [0.17898353]\nPrediction: [0.37735861], loss: [0.17862574]\nPrediction: [0.37778125], loss: [0.17826867]\nPrediction: [0.37820347], loss: [0.17791231]\nPrediction: [0.37862527], loss: [0.17755667]\nPrediction: [0.37904664], loss: [0.17720173]\nPrediction: [0.37946759], loss: [0.1768475]\nPrediction: [0.37988813], loss: [0.17649399]\nPrediction: [0.38030824], loss: [0.17614117]\nPrediction: [0.38072793], loss: [0.17578907]\nPrediction: [0.3811472], loss: [0.17543767]\nPrediction: [0.38156606], loss: [0.17508697]\nPrediction: [0.38198449], loss: [0.17473697]\nPrediction: [0.3824025], loss: [0.17438767]\nPrediction: [0.3828201], loss: [0.17403907]\nPrediction: [0.38323728], loss: [0.17369116]\nPrediction: [0.38365404], loss: [0.17334395]\nPrediction: [0.38407039], loss: [0.17299744]\nPrediction: [0.38448632], loss: [0.17265162]\nPrediction: [0.38490183], loss: [0.17230649]\nPrediction: [0.38531693], loss: [0.17196205]\nPrediction: [0.38573162], loss: [0.17161829]\nPrediction: [0.38614588], loss: [0.17127523]\nPrediction: [0.38655974], loss: [0.17093285]\nPrediction: [0.38697318], loss: [0.17059116]\nPrediction: [0.38738621], loss: [0.17025014]\nPrediction: [0.38779882], loss: [0.16990981]\nPrediction: [0.38821102], loss: [0.16957016]\nPrediction: [0.38862281], loss: [0.16923119]\nPrediction: [0.38903419], loss: [0.1688929]\nPrediction: [0.38944515], loss: [0.16855528]\nPrediction: [0.38985571], loss: [0.16821834]\nPrediction: [0.39026585], loss: [0.16788207]\nPrediction: [0.39067559], loss: [0.16754648]\nPrediction: [0.39108491], loss: [0.16721155]\nPrediction: [0.39149382], loss: [0.1668773]\nPrediction: [0.39190233], loss: [0.16654371]\nPrediction: [0.39231043], loss: [0.16621079]\nPrediction: [0.39271812], loss: [0.16587853]\nPrediction: [0.3931254], loss: [0.16554694]\nPrediction: [0.39353227], loss: [0.16521601]\nPrediction: [0.39393874], loss: [0.16488574]\nPrediction: [0.3943448], loss: [0.16455614]\nPrediction: [0.39475046], loss: [0.16422719]\nPrediction: [0.39515571], loss: [0.1638989]\nPrediction: [0.39556055], loss: [0.16357127]\nPrediction: [0.39596499], loss: [0.16324429]\nPrediction: [0.39636903], loss: [0.16291796]\nPrediction: [0.39677266], loss: [0.16259229]\nPrediction: [0.39717589], loss: [0.16226727]\nPrediction: [0.39757871], loss: [0.16194289]\nPrediction: [0.39798113], loss: [0.16161917]\nPrediction: [0.39838315], loss: [0.16129609]\n"
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    y_pred = neural_network(weight, input)\n",
    "    error = mse(y_pred, y_true)\n",
    "    print(f\"Prediction: {y_pred}, loss: {error}\")\n",
    "    value = y_pred - y_true\n",
    "    grad = value * input\n",
    "    weight = weight - learning_rate * grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent iterations with medium learning_rate\n",
    "learning_rate = 0.01\n",
    "\n",
    "weight = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Prediction: [0.3], loss: [0.25]\nPrediction: [0.305], loss: [0.245025]\nPrediction: [0.30995], loss: [0.240149]\nPrediction: [0.3148505], loss: [0.23537004]\nPrediction: [0.31970199], loss: [0.23068617]\nPrediction: [0.32450498], loss: [0.22609552]\nPrediction: [0.32925993], loss: [0.22159622]\nPrediction: [0.33396733], loss: [0.21718645]\nPrediction: [0.33862765], loss: [0.21286444]\nPrediction: [0.34324138], loss: [0.20862844]\nPrediction: [0.34780896], loss: [0.20447673]\nPrediction: [0.35233087], loss: [0.20040765]\nPrediction: [0.35680756], loss: [0.19641954]\nPrediction: [0.36123949], loss: [0.19251079]\nPrediction: [0.36562709], loss: [0.18867982]\nPrediction: [0.36997082], loss: [0.18492509]\nPrediction: [0.37427111], loss: [0.18124508]\nPrediction: [0.3785284], loss: [0.17763831]\nPrediction: [0.38274312], loss: [0.1741033]\nPrediction: [0.38691569], loss: [0.17063865]\nPrediction: [0.39104653], loss: [0.16724294]\nPrediction: [0.39513607], loss: [0.16391481]\nPrediction: [0.39918471], loss: [0.1606529]\nPrediction: [0.40319286], loss: [0.15745591]\nPrediction: [0.40716093], loss: [0.15432254]\nPrediction: [0.41108932], loss: [0.15125152]\nPrediction: [0.41497843], loss: [0.14824161]\nPrediction: [0.41882864], loss: [0.1452916]\nPrediction: [0.42264036], loss: [0.1424003]\nPrediction: [0.42641395], loss: [0.13956653]\nPrediction: [0.43014981], loss: [0.13678916]\nPrediction: [0.43384832], loss: [0.13406706]\nPrediction: [0.43750983], loss: [0.13139912]\nPrediction: [0.44113473], loss: [0.12878428]\nPrediction: [0.44472339], loss: [0.12622147]\nPrediction: [0.44827615], loss: [0.12370966]\nPrediction: [0.45179339], loss: [0.12124784]\nPrediction: [0.45527546], loss: [0.11883501]\nPrediction: [0.4587227], loss: [0.11647019]\nPrediction: [0.46213548], loss: [0.11415244]\nPrediction: [0.46551412], loss: [0.1118808]\nPrediction: [0.46885898], loss: [0.10965438]\nPrediction: [0.47217039], loss: [0.10747225]\nPrediction: [0.47544869], loss: [0.10533356]\nPrediction: [0.4786942], loss: [0.10323742]\nPrediction: [0.48190726], loss: [0.10118299]\nPrediction: [0.48508818], loss: [0.09916945]\nPrediction: [0.4882373], loss: [0.09719598]\nPrediction: [0.49135493], loss: [0.09526178]\nPrediction: [0.49444138], loss: [0.09336607]\nPrediction: [0.49749697], loss: [0.09150809]\nPrediction: [0.500522], loss: [0.08968707]\nPrediction: [0.50351678], loss: [0.0879023]\nPrediction: [0.50648161], loss: [0.08615305]\nPrediction: [0.50941679], loss: [0.0844386]\nPrediction: [0.51232263], loss: [0.08275827]\nPrediction: [0.5151994], loss: [0.08111138]\nPrediction: [0.5180474], loss: [0.07949727]\nPrediction: [0.52086693], loss: [0.07791527]\nPrediction: [0.52365826], loss: [0.07636476]\nPrediction: [0.52642168], loss: [0.0748451]\nPrediction: [0.52915746], loss: [0.07335568]\nPrediction: [0.53186589], loss: [0.0718959]\nPrediction: [0.53454723], loss: [0.07046517]\nPrediction: [0.53720176], loss: [0.06906292]\nPrediction: [0.53982974], loss: [0.06768856]\nPrediction: [0.54243144], loss: [0.06634156]\nPrediction: [0.54500713], loss: [0.06502137]\nPrediction: [0.54755706], loss: [0.06372744]\nPrediction: [0.55008149], loss: [0.06245926]\nPrediction: [0.55258067], loss: [0.06121632]\nPrediction: [0.55505486], loss: [0.05999812]\nPrediction: [0.55750431], loss: [0.05880416]\nPrediction: [0.55992927], loss: [0.05763395]\nPrediction: [0.56232998], loss: [0.05648704]\nPrediction: [0.56470668], loss: [0.05536295]\nPrediction: [0.56705961], loss: [0.05426122]\nPrediction: [0.56938902], loss: [0.05318143]\nPrediction: [0.57169513], loss: [0.05212312]\nPrediction: [0.57397817], loss: [0.05108587]\nPrediction: [0.57623839], loss: [0.05006926]\nPrediction: [0.57847601], loss: [0.04907288]\nPrediction: [0.58069125], loss: [0.04809633]\nPrediction: [0.58288434], loss: [0.04713921]\nPrediction: [0.58505549], loss: [0.04620114]\nPrediction: [0.58720494], loss: [0.04528174]\nPrediction: [0.58933289], loss: [0.04438063]\nPrediction: [0.59143956], loss: [0.04349746]\nPrediction: [0.59352516], loss: [0.04263186]\nPrediction: [0.59558991], loss: [0.04178348]\nPrediction: [0.59763401], loss: [0.04095199]\nPrediction: [0.59965767], loss: [0.04013705]\nPrediction: [0.6016611], loss: [0.03933832]\nPrediction: [0.60364449], loss: [0.03855549]\nPrediction: [0.60560804], loss: [0.03778823]\nPrediction: [0.60755196], loss: [0.03703625]\nPrediction: [0.60947644], loss: [0.03629923]\nPrediction: [0.61138168], loss: [0.03557687]\nPrediction: [0.61326786], loss: [0.03486889]\nPrediction: [0.61513518], loss: [0.034175]\nPrediction: [0.61698383], loss: [0.03349492]\nPrediction: [0.61881399], loss: [0.03282837]\nPrediction: [0.62062585], loss: [0.03217509]\nPrediction: [0.62241959], loss: [0.0315348]\nPrediction: [0.6241954], loss: [0.03090726]\nPrediction: [0.62595344], loss: [0.0302922]\nPrediction: [0.62769391], loss: [0.02968939]\nPrediction: [0.62941697], loss: [0.02909857]\nPrediction: [0.6311228], loss: [0.02851951]\nPrediction: [0.63281157], loss: [0.02795197]\nPrediction: [0.63448346], loss: [0.02739573]\nPrediction: [0.63613862], loss: [0.02685055]\nPrediction: [0.63777724], loss: [0.02631623]\nPrediction: [0.63939946], loss: [0.02579253]\nPrediction: [0.64100547], loss: [0.02527926]\nPrediction: [0.64259541], loss: [0.0247762]\nPrediction: [0.64416946], loss: [0.02428316]\nPrediction: [0.64572776], loss: [0.02379992]\nPrediction: [0.64727049], loss: [0.0233263]\nPrediction: [0.64879778], loss: [0.02286211]\nPrediction: [0.6503098], loss: [0.02240715]\nPrediction: [0.65180671], loss: [0.02196125]\nPrediction: [0.65328864], loss: [0.02152422]\nPrediction: [0.65475575], loss: [0.02109589]\nPrediction: [0.6562082], loss: [0.02067608]\nPrediction: [0.65764611], loss: [0.02026463]\nPrediction: [0.65906965], loss: [0.01986136]\nPrediction: [0.66047896], loss: [0.01946612]\nPrediction: [0.66187417], loss: [0.01907875]\nPrediction: [0.66325542], loss: [0.01869908]\nPrediction: [0.66462287], loss: [0.01832697]\nPrediction: [0.66597664], loss: [0.01796226]\nPrediction: [0.66731688], loss: [0.01760481]\nPrediction: [0.66864371], loss: [0.01725448]\nPrediction: [0.66995727], loss: [0.01691111]\nPrediction: [0.6712577], loss: [0.01657458]\nPrediction: [0.67254512], loss: [0.01624475]\nPrediction: [0.67381967], loss: [0.01592148]\nPrediction: [0.67508147], loss: [0.01560464]\nPrediction: [0.67633066], loss: [0.01529411]\nPrediction: [0.67756735], loss: [0.01498975]\nPrediction: [0.67879168], loss: [0.01469146]\nPrediction: [0.68000376], loss: [0.0143991]\nPrediction: [0.68120372], loss: [0.01411256]\nPrediction: [0.68239169], loss: [0.01383172]\nPrediction: [0.68356777], loss: [0.01355646]\nPrediction: [0.68473209], loss: [0.01328669]\nPrediction: [0.68588477], loss: [0.01302229]\nPrediction: [0.68702592], loss: [0.01276314]\nPrediction: [0.68815566], loss: [0.01250916]\nPrediction: [0.68927411], loss: [0.01226022]\nPrediction: [0.69038137], loss: [0.01201625]\nPrediction: [0.69147755], loss: [0.01177712]\nPrediction: [0.69256278], loss: [0.01154276]\nPrediction: [0.69363715], loss: [0.01131306]\nPrediction: [0.69470078], loss: [0.01108793]\nPrediction: [0.69575377], loss: [0.01086728]\nPrediction: [0.69679623], loss: [0.01065102]\nPrediction: [0.69782827], loss: [0.01043906]\nPrediction: [0.69884999], loss: [0.01023133]\nPrediction: [0.69986149], loss: [0.01002772]\nPrediction: [0.70086287], loss: [0.00982817]\nPrediction: [0.70185424], loss: [0.00963259]\nPrediction: [0.7028357], loss: [0.0094409]\nPrediction: [0.70380734], loss: [0.00925303]\nPrediction: [0.70476927], loss: [0.00906889]\nPrediction: [0.70572158], loss: [0.00888842]\nPrediction: [0.70666436], loss: [0.00871154]\nPrediction: [0.70759772], loss: [0.00853818]\nPrediction: [0.70852174], loss: [0.00836827]\nPrediction: [0.70943652], loss: [0.00820174]\nPrediction: [0.71034216], loss: [0.00803853]\nPrediction: [0.71123874], loss: [0.00787856]\nPrediction: [0.71212635], loss: [0.00772178]\nPrediction: [0.71300509], loss: [0.00756812]\nPrediction: [0.71387503], loss: [0.00741751]\nPrediction: [0.71473628], loss: [0.0072699]\nPrediction: [0.71558892], loss: [0.00712523]\nPrediction: [0.71643303], loss: [0.00698344]\nPrediction: [0.7172687], loss: [0.00684447]\nPrediction: [0.71809602], loss: [0.00670826]\nPrediction: [0.71891505], loss: [0.00657477]\nPrediction: [0.7197259], loss: [0.00644393]\nPrediction: [0.72052865], loss: [0.0063157]\nPrediction: [0.72132336], loss: [0.00619001]\nPrediction: [0.72211013], loss: [0.00606683]\nPrediction: [0.72288902], loss: [0.0059461]\nPrediction: [0.72366013], loss: [0.00582778]\nPrediction: [0.72442353], loss: [0.0057118]\nPrediction: [0.7251793], loss: [0.00559814]\nPrediction: [0.7259275], loss: [0.00548673]\nPrediction: [0.72666823], loss: [0.00537755]\nPrediction: [0.72740155], loss: [0.00527054]\nPrediction: [0.72812753], loss: [0.00516565]\nPrediction: [0.72884626], loss: [0.00506286]\nPrediction: [0.72955779], loss: [0.0049621]\nPrediction: [0.73026222], loss: [0.00486336]\nPrediction: [0.73095959], loss: [0.00476658]\nPrediction: [0.73165], loss: [0.00467172]\nPrediction: [0.7323335], loss: [0.00457876]\n"
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    y_pred = neural_network(weight, input)\n",
    "    error = mse(y_pred, y_true)\n",
    "    print(f\"Prediction: {y_pred}, loss: {error}\")\n",
    "    value = y_pred - y_true\n",
    "    grad = value * input\n",
    "    weight = weight - learning_rate * grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent iterations with high learning_rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "weight = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Prediction: [0.3], loss: [0.25]\nPrediction: [0.35], loss: [0.2025]\nPrediction: [0.395], loss: [0.164025]\nPrediction: [0.4355], loss: [0.13286025]\nPrediction: [0.47195], loss: [0.1076168]\nPrediction: [0.504755], loss: [0.08716961]\nPrediction: [0.5342795], loss: [0.07060738]\nPrediction: [0.56085155], loss: [0.05719198]\nPrediction: [0.58476639], loss: [0.0463255]\nPrediction: [0.60628976], loss: [0.03752366]\nPrediction: [0.62566078], loss: [0.03039416]\nPrediction: [0.6430947], loss: [0.02461927]\nPrediction: [0.65878523], loss: [0.01994161]\nPrediction: [0.67290671], loss: [0.0161527]\nPrediction: [0.68561604], loss: [0.01308369]\nPrediction: [0.69705443], loss: [0.01059779]\nPrediction: [0.70734899], loss: [0.00858421]\nPrediction: [0.71661409], loss: [0.00695321]\nPrediction: [0.72495268], loss: [0.0056321]\nPrediction: [0.73245741], loss: [0.004562]\nPrediction: [0.73921167], loss: [0.00369522]\nPrediction: [0.74529051], loss: [0.00299313]\nPrediction: [0.75076145], loss: [0.00242443]\nPrediction: [0.75568531], loss: [0.00196379]\nPrediction: [0.76011678], loss: [0.00159067]\nPrediction: [0.7641051], loss: [0.00128844]\nPrediction: [0.76769459], loss: [0.00104364]\nPrediction: [0.77092513], loss: [0.00084535]\nPrediction: [0.77383262], loss: [0.00068473]\nPrediction: [0.77644936], loss: [0.00055463]\nPrediction: [0.77880442], loss: [0.00044925]\nPrediction: [0.78092398], loss: [0.00036389]\nPrediction: [0.78283158], loss: [0.00029475]\nPrediction: [0.78454842], loss: [0.00023875]\nPrediction: [0.78609358], loss: [0.00019339]\nPrediction: [0.78748422], loss: [0.00015664]\nPrediction: [0.7887358], loss: [0.00012688]\nPrediction: [0.78986222], loss: [0.00010277]\nPrediction: [0.790876], loss: [8.32474091e-05]\nPrediction: [0.7917884], loss: [6.74304014e-05]\nPrediction: [0.79260956], loss: [5.46186251e-05]\nPrediction: [0.7933486], loss: [4.42410864e-05]\nPrediction: [0.79401374], loss: [3.58352799e-05]\nPrediction: [0.79461237], loss: [2.90265768e-05]\nPrediction: [0.79515113], loss: [2.35115272e-05]\nPrediction: [0.79563602], loss: [1.9044337e-05]\nPrediction: [0.79607242], loss: [1.5425913e-05]\nPrediction: [0.79646517], loss: [1.24949895e-05]\nPrediction: [0.79681866], loss: [1.01209415e-05]\nPrediction: [0.79713679], loss: [8.19796262e-06]\nPrediction: [0.79742311], loss: [6.64034972e-06]\nPrediction: [0.7976808], loss: [5.37868327e-06]\nPrediction: [0.79791272], loss: [4.35673345e-06]\nPrediction: [0.79812145], loss: [3.5289541e-06]\nPrediction: [0.7983093], loss: [2.85845282e-06]\nPrediction: [0.79847837], loss: [2.31534678e-06]\nPrediction: [0.79863054], loss: [1.87543089e-06]\nPrediction: [0.79876748], loss: [1.51909902e-06]\nPrediction: [0.79889073], loss: [1.23047021e-06]\nPrediction: [0.79900166], loss: [9.9668087e-07]\nPrediction: [0.79910149], loss: [8.07311504e-07]\nPrediction: [0.79919135], loss: [6.53922319e-07]\nPrediction: [0.79927221], loss: [5.29677078e-07]\nPrediction: [0.79934499], loss: [4.29038433e-07]\nPrediction: [0.79941049], loss: [3.47521131e-07]\nPrediction: [0.79946944], loss: [2.81492116e-07]\nPrediction: [0.7995225], loss: [2.28008614e-07]\nPrediction: [0.79957025], loss: [1.84686977e-07]\nPrediction: [0.79961322], loss: [1.49596452e-07]\nPrediction: [0.7996519], loss: [1.21173126e-07]\nPrediction: [0.79968671], loss: [9.81502319e-08]\nPrediction: [0.79971804], loss: [7.95016879e-08]\nPrediction: [0.79974624], loss: [6.43963672e-08]\nPrediction: [0.79977161], loss: [5.21610574e-08]\nPrediction: [0.79979445], loss: [4.22504565e-08]\nPrediction: [0.79981501], loss: [3.42228698e-08]\nPrediction: [0.79983351], loss: [2.77205245e-08]\nPrediction: [0.79985015], loss: [2.24536249e-08]\nPrediction: [0.79986514], loss: [1.81874361e-08]\nPrediction: [0.79987863], loss: [1.47318233e-08]\nPrediction: [0.79989076], loss: [1.19327768e-08]\nPrediction: [0.79990169], loss: [9.66554924e-09]\nPrediction: [0.79991152], loss: [7.82909489e-09]\nPrediction: [0.79992037], loss: [6.34156686e-09]\nPrediction: [0.79992833], loss: [5.13666916e-09]\nPrediction: [0.7999355], loss: [4.16070202e-09]\nPrediction: [0.79994195], loss: [3.37016863e-09]\nPrediction: [0.79994775], loss: [2.72983659e-09]\nPrediction: [0.79995298], loss: [2.21116764e-09]\nPrediction: [0.79995768], loss: [1.79104579e-09]\nPrediction: [0.79996191], loss: [1.45074709e-09]\nPrediction: [0.79996572], loss: [1.17510514e-09]\nPrediction: [0.79996915], loss: [9.51835165e-10]\nPrediction: [0.79997223], loss: [7.70986484e-10]\nPrediction: [0.79997501], loss: [6.24499052e-10]\nPrediction: [0.79997751], loss: [5.05844232e-10]\nPrediction: [0.79997976], loss: [4.09733828e-10]\nPrediction: [0.79998178], loss: [3.31884401e-10]\nPrediction: [0.7999836], loss: [2.68826364e-10]\nPrediction: [0.79998524], loss: [2.17749355e-10]\nPrediction: [0.79998672], loss: [1.76376978e-10]\nPrediction: [0.79998805], loss: [1.42865352e-10]\nPrediction: [0.79998924], loss: [1.15720935e-10]\nPrediction: [0.79999032], loss: [9.37339574e-11]\nPrediction: [0.79999129], loss: [7.59245055e-11]\nPrediction: [0.79999216], loss: [6.14988495e-11]\nPrediction: [0.79999294], loss: [4.98140681e-11]\nPrediction: [0.79999365], loss: [4.03493951e-11]\nPrediction: [0.79999428], loss: [3.26830101e-11]\nPrediction: [0.79999485], loss: [2.64732381e-11]\nPrediction: [0.79999537], loss: [2.14433229e-11]\nPrediction: [0.79999583], loss: [1.73690915e-11]\nPrediction: [0.79999625], loss: [1.40689642e-11]\nPrediction: [0.79999662], loss: [1.1395861e-11]\nPrediction: [0.79999696], loss: [9.23064738e-12]\nPrediction: [0.79999727], loss: [7.47682438e-12]\nPrediction: [0.79999754], loss: [6.05622775e-12]\nPrediction: [0.79999779], loss: [4.90554447e-12]\nPrediction: [0.79999801], loss: [3.97349102e-12]\nPrediction: [0.79999821], loss: [3.21852773e-12]\nPrediction: [0.79999839], loss: [2.60700746e-12]\nPrediction: [0.79999855], loss: [2.11167604e-12]\nPrediction: [0.79999869], loss: [1.7104576e-12]\nPrediction: [0.79999882], loss: [1.38547065e-12]\nPrediction: [0.79999894], loss: [1.12223123e-12]\nPrediction: [0.79999905], loss: [9.09007295e-13]\nPrediction: [0.79999914], loss: [7.36295909e-13]\nPrediction: [0.79999923], loss: [5.96399686e-13]\nPrediction: [0.7999993], loss: [4.83083746e-13]\nPrediction: [0.79999937], loss: [3.91297834e-13]\nPrediction: [0.79999944], loss: [3.16951246e-13]\nPrediction: [0.79999949], loss: [2.56730509e-13]\nPrediction: [0.79999954], loss: [2.07951712e-13]\nPrediction: [0.79999959], loss: [1.68440887e-13]\nPrediction: [0.79999963], loss: [1.36437118e-13]\nPrediction: [0.79999967], loss: [1.10514066e-13]\nPrediction: [0.7999997], loss: [8.95163933e-14]\nPrediction: [0.79999973], loss: [7.25082786e-14]\nPrediction: [0.79999976], loss: [5.87317057e-14]\nPrediction: [0.79999978], loss: [4.75726816e-14]\nPrediction: [0.7999998], loss: [3.85338721e-14]\nPrediction: [0.79999982], loss: [3.12124364e-14]\nPrediction: [0.79999984], loss: [2.52820735e-14]\nPrediction: [0.79999986], loss: [2.04784795e-14]\nPrediction: [0.79999987], loss: [1.65875684e-14]\nPrediction: [0.79999988], loss: [1.34359304e-14]\nPrediction: [0.7999999], loss: [1.08831036e-14]\nPrediction: [0.79999991], loss: [8.81531394e-15]\nPrediction: [0.79999992], loss: [7.14040429e-15]\nPrediction: [0.79999992], loss: [5.78372747e-15]\nPrediction: [0.79999993], loss: [4.68481926e-15]\nPrediction: [0.79999994], loss: [3.7947036e-15]\nPrediction: [0.79999994], loss: [3.07370992e-15]\nPrediction: [0.79999995], loss: [2.48970503e-15]\nPrediction: [0.79999996], loss: [2.01666108e-15]\nPrediction: [0.79999996], loss: [1.63349547e-15]\nPrediction: [0.79999996], loss: [1.32313133e-15]\nPrediction: [0.79999997], loss: [1.07173638e-15]\nPrediction: [0.79999997], loss: [8.68106466e-16]\nPrediction: [0.79999997], loss: [7.03166241e-16]\nPrediction: [0.79999998], loss: [5.69564656e-16]\nPrediction: [0.79999998], loss: [4.6134737e-16]\nPrediction: [0.79999998], loss: [3.73691369e-16]\nPrediction: [0.79999998], loss: [3.02690008e-16]\nPrediction: [0.79999998], loss: [2.45178906e-16]\nPrediction: [0.79999999], loss: [1.98594915e-16]\nPrediction: [0.79999999], loss: [1.60861882e-16]\nPrediction: [0.79999999], loss: [1.30298125e-16]\nPrediction: [0.79999999], loss: [1.05541482e-16]\nPrediction: [0.79999999], loss: [8.54885995e-17]\nPrediction: [0.79999999], loss: [6.92457647e-17]\nPrediction: [0.79999999], loss: [5.60890701e-17]\nPrediction: [0.79999999], loss: [4.54321468e-17]\nPrediction: [0.79999999], loss: [3.6800039e-17]\nPrediction: [0.79999999], loss: [2.9808031e-17]\nPrediction: [0.8], loss: [2.41445055e-17]\nPrediction: [0.8], loss: [1.95570493e-17]\nPrediction: [0.8], loss: [1.58412104e-17]\nPrediction: [0.8], loss: [1.28313804e-17]\nPrediction: [0.8], loss: [1.03934183e-17]\nPrediction: [0.8], loss: [8.41866898e-18]\nPrediction: [0.8], loss: [6.8191217e-18]\nPrediction: [0.8], loss: [5.52348873e-18]\nPrediction: [0.8], loss: [4.47402602e-18]\nPrediction: [0.8], loss: [3.62396116e-18]\nPrediction: [0.8], loss: [2.9354085e-18]\nPrediction: [0.8], loss: [2.37768071e-18]\nPrediction: [0.8], loss: [1.92592132e-18]\nPrediction: [0.8], loss: [1.55999632e-18]\nPrediction: [0.8], loss: [1.26359715e-18]\nPrediction: [0.8], loss: [1.02351364e-18]\nPrediction: [0.8], loss: [8.29046051e-19]\nPrediction: [0.8], loss: [6.71527337e-19]\nPrediction: [0.8], loss: [5.43937127e-19]\nPrediction: [0.8], loss: [4.40589043e-19]\nPrediction: [0.8], loss: [3.56877099e-19]\nPrediction: [0.8], loss: [2.89070426e-19]\nPrediction: [0.8], loss: [2.34146991e-19]\nPrediction: [0.8], loss: [1.89659063e-19]\nPrediction: [0.8], loss: [1.53623867e-19]\n"
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    y_pred = neural_network(weight, input)\n",
    "    error = mse(y_pred, y_true)\n",
    "    print(f\"Prediction: {y_pred}, loss: {error}\")\n",
    "    value = y_pred - y_true\n",
    "    grad = value * input\n",
    "    weight = weight - learning_rate * grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent iterations with too high learning_rate\n",
    "learning_rate = 10\n",
    "\n",
    "weight = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Prediction: [0.3], loss: [0.25]\nPrediction: [5.3], loss: [20.25]\nPrediction: [-39.7], loss: [1640.25]\nPrediction: [365.3], loss: [132860.25]\nPrediction: [-3279.7], loss: [10761680.25]\nPrediction: [29525.3], loss: [8.716961e+08]\nPrediction: [-265719.7], loss: [7.06073841e+10]\nPrediction: [2391485.3], loss: [5.71919811e+12]\nPrediction: [-21523359.7], loss: [4.63255047e+14]\nPrediction: [1.93710245e+08], loss: [3.75236588e+16]\nPrediction: [-1.7433922e+09], loss: [3.03941636e+18]\nPrediction: [1.56905298e+10], loss: [2.46192726e+20]\nPrediction: [-1.41214768e+11], loss: [1.99416108e+22]\nPrediction: [1.27093291e+12], loss: [1.61527047e+24]\nPrediction: [-1.14383962e+13], loss: [1.30836908e+26]\nPrediction: [1.02945566e+14], loss: [1.05977896e+28]\nPrediction: [-9.26510094e+14], loss: [8.58420955e+29]\nPrediction: [8.33859085e+15], loss: [6.95320974e+31]\nPrediction: [-7.50473176e+16], loss: [5.63209989e+33]\nPrediction: [6.75425859e+17], loss: [4.56200091e+35]\nPrediction: [-6.07883273e+18], loss: [3.69522074e+37]\nPrediction: [5.47094946e+19], loss: [2.9931288e+39]\nPrediction: [-4.92385451e+20], loss: [2.42443432e+41]\nPrediction: [4.43146906e+21], loss: [1.9637918e+43]\nPrediction: [-3.98832215e+22], loss: [1.59067136e+45]\nPrediction: [3.58948994e+23], loss: [1.2884438e+47]\nPrediction: [-3.23054094e+24], loss: [1.04363948e+49]\nPrediction: [2.90748685e+25], loss: [8.45347978e+50]\nPrediction: [-2.61673817e+26], loss: [6.84731862e+52]\nPrediction: [2.35506435e+27], loss: [5.54632809e+54]\nPrediction: [-2.11955791e+28], loss: [4.49252575e+56]\nPrediction: [1.90760212e+29], loss: [3.63894586e+58]\nPrediction: [-1.71684191e+30], loss: [2.94754614e+60]\nPrediction: [1.54515772e+31], loss: [2.38751238e+62]\nPrediction: [-1.39064195e+32], loss: [1.93388503e+64]\nPrediction: [1.25157775e+33], loss: [1.56644687e+66]\nPrediction: [-1.12641998e+34], loss: [1.26882197e+68]\nPrediction: [1.01377798e+35], loss: [1.02774579e+70]\nPrediction: [-9.12400182e+35], loss: [8.32474091e+71]\nPrediction: [8.21160163e+36], loss: [6.74304014e+73]\nPrediction: [-7.39044147e+37], loss: [5.46186251e+75]\nPrediction: [6.65139732e+38], loss: [4.42410864e+77]\nPrediction: [-5.98625759e+39], loss: [3.58352799e+79]\nPrediction: [5.38763183e+40], loss: [2.90265768e+81]\nPrediction: [-4.84886865e+41], loss: [2.35115272e+83]\nPrediction: [4.36398178e+42], loss: [1.9044337e+85]\nPrediction: [-3.92758361e+43], loss: [1.5425913e+87]\nPrediction: [3.53482525e+44], loss: [1.24949895e+89]\nPrediction: [-3.18134272e+45], loss: [1.01209415e+91]\nPrediction: [2.86320845e+46], loss: [8.19796262e+92]\nPrediction: [-2.5768876e+47], loss: [6.64034972e+94]\nPrediction: [2.31919884e+48], loss: [5.37868327e+96]\nPrediction: [-2.08727896e+49], loss: [4.35673345e+98]\nPrediction: [1.87855106e+50], loss: [3.5289541e+100]\nPrediction: [-1.69069596e+51], loss: [2.85845282e+102]\nPrediction: [1.52162636e+52], loss: [2.31534678e+104]\nPrediction: [-1.36946372e+53], loss: [1.87543089e+106]\nPrediction: [1.23251735e+54], loss: [1.51909902e+108]\nPrediction: [-1.10926562e+55], loss: [1.23047021e+110]\nPrediction: [9.98339056e+55], loss: [9.9668087e+111]\nPrediction: [-8.9850515e+56], loss: [8.07311504e+113]\nPrediction: [8.08654635e+57], loss: [6.53922319e+115]\nPrediction: [-7.27789171e+58], loss: [5.29677078e+117]\nPrediction: [6.55010254e+59], loss: [4.29038433e+119]\nPrediction: [-5.89509229e+60], loss: [3.47521131e+121]\nPrediction: [5.30558306e+61], loss: [2.81492116e+123]\nPrediction: [-4.77502475e+62], loss: [2.28008614e+125]\nPrediction: [4.29752228e+63], loss: [1.84686977e+127]\nPrediction: [-3.86777005e+64], loss: [1.49596452e+129]\nPrediction: [3.48099305e+65], loss: [1.21173126e+131]\nPrediction: [-3.13289374e+66], loss: [9.81502319e+132]\nPrediction: [2.81960437e+67], loss: [7.95016879e+134]\nPrediction: [-2.53764393e+68], loss: [6.43963672e+136]\nPrediction: [2.28387954e+69], loss: [5.21610574e+138]\nPrediction: [-2.05549158e+70], loss: [4.22504565e+140]\nPrediction: [1.84994243e+71], loss: [3.42228698e+142]\nPrediction: [-1.66494818e+72], loss: [2.77205245e+144]\nPrediction: [1.49845336e+73], loss: [2.24536249e+146]\nPrediction: [-1.34860803e+74], loss: [1.81874361e+148]\nPrediction: [1.21374723e+75], loss: [1.47318233e+150]\nPrediction: [-1.0923725e+76], loss: [1.19327768e+152]\nPrediction: [9.83135252e+76], loss: [9.66554924e+153]\nPrediction: [-8.84821727e+77], loss: [7.82909489e+155]\nPrediction: [7.96339554e+78], loss: [6.34156686e+157]\nPrediction: [-7.16705599e+79], loss: [5.13666916e+159]\nPrediction: [6.45035039e+80], loss: [4.16070202e+161]\nPrediction: [-5.80531535e+81], loss: [3.37016863e+163]\nPrediction: [5.22478382e+82], loss: [2.72983659e+165]\nPrediction: [-4.70230543e+83], loss: [2.21116764e+167]\nPrediction: [4.23207489e+84], loss: [1.79104579e+169]\nPrediction: [-3.8088674e+85], loss: [1.45074709e+171]\nPrediction: [3.42798066e+86], loss: [1.17510514e+173]\nPrediction: [-3.0851826e+87], loss: [9.51835165e+174]\nPrediction: [2.77666434e+88], loss: [7.70986484e+176]\nPrediction: [-2.4989979e+89], loss: [6.24499052e+178]\nPrediction: [2.24909811e+90], loss: [5.05844232e+180]\nPrediction: [-2.0241883e+91], loss: [4.09733828e+182]\nPrediction: [1.82176947e+92], loss: [3.31884401e+184]\nPrediction: [-1.63959252e+93], loss: [2.68826364e+186]\nPrediction: [1.47563327e+94], loss: [2.17749355e+188]\nPrediction: [-1.32806994e+95], loss: [1.76376978e+190]\nPrediction: [1.19526295e+96], loss: [1.42865352e+192]\nPrediction: [-1.07573665e+97], loss: [1.15720935e+194]\nPrediction: [9.68162989e+97], loss: [9.37339574e+195]\nPrediction: [-8.71346691e+98], loss: [7.59245055e+197]\nPrediction: [7.84212021e+99], loss: [6.14988495e+199]\nPrediction: [-7.05790819e+100], loss: [4.98140681e+201]\nPrediction: [6.35211737e+101], loss: [4.03493951e+203]\nPrediction: [-5.71690564e+102], loss: [3.26830101e+205]\nPrediction: [5.14521507e+103], loss: [2.64732381e+207]\nPrediction: [-4.63069357e+104], loss: [2.14433229e+209]\nPrediction: [4.16762421e+105], loss: [1.73690915e+211]\nPrediction: [-3.75086179e+106], loss: [1.40689642e+213]\nPrediction: [3.37577561e+107], loss: [1.1395861e+215]\nPrediction: [-3.03819805e+108], loss: [9.23064738e+216]\nPrediction: [2.73437824e+109], loss: [7.47682438e+218]\nPrediction: [-2.46094042e+110], loss: [6.05622775e+220]\nPrediction: [2.21484638e+111], loss: [4.90554447e+222]\nPrediction: [-1.99336174e+112], loss: [3.97349102e+224]\nPrediction: [1.79402557e+113], loss: [3.21852773e+226]\nPrediction: [-1.61462301e+114], loss: [2.60700746e+228]\nPrediction: [1.45316071e+115], loss: [2.11167604e+230]\nPrediction: [-1.30784464e+116], loss: [1.7104576e+232]\nPrediction: [1.17706017e+117], loss: [1.38547065e+234]\nPrediction: [-1.05935416e+118], loss: [1.12223123e+236]\nPrediction: [9.53418741e+118], loss: [9.09007295e+237]\nPrediction: [-8.58076867e+119], loss: [7.36295909e+239]\nPrediction: [7.7226918e+120], loss: [5.96399686e+241]\nPrediction: [-6.95042262e+121], loss: [4.83083746e+243]\nPrediction: [6.25538036e+122], loss: [3.91297834e+245]\nPrediction: [-5.62984232e+123], loss: [3.16951246e+247]\nPrediction: [5.06685809e+124], loss: [2.56730509e+249]\nPrediction: [-4.56017228e+125], loss: [2.07951712e+251]\nPrediction: [4.10415505e+126], loss: [1.68440887e+253]\nPrediction: [-3.69373955e+127], loss: [1.36437118e+255]\nPrediction: [3.32436559e+128], loss: [1.10514066e+257]\nPrediction: [-2.99192903e+129], loss: [8.95163934e+258]\nPrediction: [2.69273613e+130], loss: [7.25082786e+260]\nPrediction: [-2.42346252e+131], loss: [5.87317057e+262]\nPrediction: [2.18111627e+132], loss: [4.75726816e+264]\nPrediction: [-1.96300464e+133], loss: [3.85338721e+266]\nPrediction: [1.76670417e+134], loss: [3.12124364e+268]\nPrediction: [-1.59003376e+135], loss: [2.52820735e+270]\nPrediction: [1.43103038e+136], loss: [2.04784795e+272]\nPrediction: [-1.28792734e+137], loss: [1.65875684e+274]\nPrediction: [1.15913461e+138], loss: [1.34359304e+276]\nPrediction: [-1.04322115e+139], loss: [1.08831036e+278]\nPrediction: [9.38899033e+139], loss: [8.81531395e+279]\nPrediction: [-8.4500913e+140], loss: [7.1404043e+281]\nPrediction: [7.60508217e+141], loss: [5.78372748e+283]\nPrediction: [-6.84457395e+142], loss: [4.68481926e+285]\nPrediction: [6.16011656e+143], loss: [3.7947036e+287]\nPrediction: [-5.5441049e+144], loss: [3.07370992e+289]\nPrediction: [4.98969441e+145], loss: [2.48970503e+291]\nPrediction: [-4.49072497e+146], loss: [2.01666108e+293]\nPrediction: [4.04165247e+147], loss: [1.63349547e+295]\nPrediction: [-3.63748723e+148], loss: [1.32313133e+297]\nPrediction: [3.2737385e+149], loss: [1.07173638e+299]\nPrediction: [-2.94636465e+150], loss: [8.68106467e+300]\nPrediction: [2.65172819e+151], loss: [7.03166238e+302]\nPrediction: [-2.38655537e+152], loss: [5.69564653e+304]\nPrediction: [2.14789983e+153], loss: [4.61347369e+306]\nPrediction: [-1.93310985e+154], loss: [inf]\nPrediction: [1.73979886e+155], loss: [inf]\nPrediction: [-1.56581898e+156], loss: [inf]\nPrediction: [1.40923708e+157], loss: [inf]\nPrediction: [-1.26831337e+158], loss: [inf]\nPrediction: [1.14148203e+159], loss: [inf]\nPrediction: [-1.02733383e+160], loss: [inf]\nPrediction: [9.24600448e+160], loss: [inf]\nPrediction: [-8.32140403e+161], loss: [inf]\nPrediction: [7.48926363e+162], loss: [inf]\nPrediction: [-6.74033727e+163], loss: [inf]\nPrediction: [6.06630354e+164], loss: [inf]\nPrediction: [-5.45967319e+165], loss: [inf]\nPrediction: [4.91370587e+166], loss: [inf]\nPrediction: [-4.42233528e+167], loss: [inf]\nPrediction: [3.98010175e+168], loss: [inf]\nPrediction: [-3.58209158e+169], loss: [inf]\nPrediction: [3.22388242e+170], loss: [inf]\nPrediction: [-2.90149418e+171], loss: [inf]\nPrediction: [2.61134476e+172], loss: [inf]\nPrediction: [-2.35021028e+173], loss: [inf]\nPrediction: [2.11518926e+174], loss: [inf]\nPrediction: [-1.90367033e+175], loss: [inf]\nPrediction: [1.7133033e+176], loss: [inf]\nPrediction: [-1.54197297e+177], loss: [inf]\nPrediction: [1.38777567e+178], loss: [inf]\nPrediction: [-1.2489981e+179], loss: [inf]\nPrediction: [1.12409829e+180], loss: [inf]\nPrediction: [-1.01168846e+181], loss: [inf]\nPrediction: [9.10519617e+181], loss: [inf]\nPrediction: [-8.19467656e+182], loss: [inf]\nPrediction: [7.3752089e+183], loss: [inf]\nPrediction: [-6.63768801e+184], loss: [inf]\nPrediction: [5.97391921e+185], loss: [inf]\nPrediction: [-5.37652729e+186], loss: [inf]\nPrediction: [4.83887456e+187], loss: [inf]\nPrediction: [-4.3549871e+188], loss: [inf]\nPrediction: [3.91948839e+189], loss: [inf]\n"
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    y_pred = neural_network(weight, input)\n",
    "    error = mse(y_pred, y_true)\n",
    "    print(f\"Prediction: {y_pred}, loss: {error}\")\n",
    "    value = y_pred - y_true\n",
    "    grad = value * input\n",
    "    weight = weight - learning_rate * grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}